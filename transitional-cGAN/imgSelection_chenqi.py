#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Mar 19 18:32:17 2022

@author: guo.1648
"""

# the code to select images generated by cGAN for training.
# there are 2 different options for selecting:
# (1) randomly select;
# (2) select those whose pred_prob > thresh using a pretrained classifier.
# Later these slected images will be combined with orig images and then for classification.


import cv2
import os
import numpy as np
import shutil
import pickle
import random

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.optim
import torch.multiprocessing as mp
import torch.utils.data
import torch.utils.data.distributed
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from PIL import Image



### For Insects:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Insects_128-007000/t/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Insects_128-007000-step2/b/'
### For Fungi:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Fungi_128-006800/d/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Fungi_128-006800_step2/a/'
### For Birds:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Birds_128-011200/e/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Birds_128-011200_step2/based on step1 thresh10/f/'
### For Reptiles:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Reptiles_128-011200/f/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Reptiles_128-011200_step2/based on step1 thresh10/c/'
### For Amphibians:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Amphibians_128-009200/c/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/Amphibians_128-009200_step2/based on step1 thresh10/a/'
### For flowers:
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/flowers_128-007600/b/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/flowers_128-007600_step2/based on step1 thresh15/a/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/UTKFace_128-004200/b/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/UTKFace_128-004200_step2/b/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/scene_128-004800/a/'
#srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate/scene_128-004800_step2/a/'
srcRootDir_GAN_ALL = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/generate_without_cls_select/Amphibians_2ndTry/'


srcRootDir_orig = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/data/iNaturalist/train/Amphibians/' #'/eecf/cbcsl/data100b/Chenqi/imbalanced_data/data/UTKFace/UTKFace/utkface_aligned_cropped/group_by_ethnicity/train/' #'/eecf/cbcsl/data100b/Chenqi/imbalanced_data/data/scene/scene/train/' #'/eecf/cbcsl/data100b/Chenqi/imbalanced_data/data/flowers/train/'

opt = 1 #2 #1

# only needed for option 2:
genProb_Flag = True # only be True for the first time!!!
prob_thresh = 30 # 10, 15, 20, (25), 30
gpu = 1
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_orig_iNaturalist/Insects/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Insects/opt2/step1/thresh_10/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_orig_iNaturalist/Fungi/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Fungi/opt2/step1/thresh_10/ckpt/checkpoint_Epoch100.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Fungi/opt2/step1/thresh_15/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_orig_iNaturalist/Birds/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Birds/opt2/step1/thresh_10/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_orig_iNaturalist/Reptiles/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Reptiles/opt2/step1/thresh_10/ckpt/checkpoint_bestAcc1.pth.tar'
###clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_orig_iNaturalist/Amphibians/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_gan_v3cls_iNaturalist/Amphibians/step1_v2/thresh_12/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/iNaturalist_eachSubCls/cls_res18_cGAN_iNaturalist/Amphibians/opt2/step1/thresh_10/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/flowers/cls_res18_orig/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/flowers/cls_res18_cGAN/opt2/step1/thresh_15/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/UTKFace/cls_res18_orig/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/UTKFace/cls_res18_cGAN/opt2/step1/thresh_25/ckpt/checkpoint_bestAcc1.pth.tar'
#clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/scene/cls_res18_orig/ckpt/checkpoint_bestAcc1.pth.tar'
clsNetwork = '/eecf/cbcsl/data100b/Chenqi/imbalanced_data/resnet/results_fromScratch/scene/cls_res18_cGAN/opt2/step1/thresh_30/ckpt/checkpoint_bestAcc1.pth.tar'

predPklRootDir = srcRootDir_GAN_ALL

dstRootDir_opt = '/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/aug-data_without_cls_select/Amphibians_2ndTry/' #'/eecf/cbcsl/data100b/Chenqi/transitional-cGAN/results/aug-data/scene/opt'+str(opt)+'/'
if opt == 2:
    dstRootDir_opt = dstRootDir_opt + 'step2/thresh_'+str(prob_thresh)+'/'

total_num_needed = 2770 #10000 #3000 #1121 #993

"""
## for Insects:
pred_mapto_actual_dict = {0: '100', 1: '101', 2: '102', 3: '103', 4: '104', 5: '105',
                          6: '106', 7: '107', 8: '108', 9: '109', 10: '110', 11: '111',
                          12: '112', 13: '113', 14: '114', 15: '115', 16: '116', 17: '117',
                          18: '118', 19: '119', 20: '12', 21: '120', 22: '121', 23: '122',
                          24: '123', 25: '124', 26: '125', 27: '126', 28: '127', 29: '128',
                          30: '129', 31: '13', 32: '130', 33: '131', 34: '132', 35: '133',
                          36: '134', 37: '135', 38: '136', 39: '137', 40: '138', 41: '139',
                          42: '14', 43: '140', 44: '141', 45: '142', 46: '143', 47: '144',
                          48: '145', 49: '146', 50: '147', 51: '148', 52: '149', 53: '15',
                          54: '150', 55: '151', 56: '152', 57: '16', 58: '17', 59: '18',
                          60: '19', 61: '20', 62: '21', 63: '22', 64: '23', 65: '24',
                          66: '25', 67: '26', 68: '27', 69: '28', 70: '29', 71: '30',
                          72: '31', 73: '32', 74: '33', 75: '34', 76: '35', 77: '36',
                          78: '37', 79: '38', 80: '39', 81: '40', 82: '41', 83: '42',
                          84: '43', 85: '44', 86: '45', 87: '46', 88: '47', 89: '48',
                          90: '49', 91: '50', 92: '51', 93: '52', 94: '53', 95: '54',
                          96: '55', 97: '56', 98: '57', 99: '58', 100: '59', 101: '60',
                          102: '61', 103: '62', 104: '63', 105: '64', 106: '65', 107: '66',
                          108: '67', 109: '68', 110: '69', 111: '70', 112: '71', 113: '72',
                          114: '73', 115: '74', 116: '75', 117: '76', 118: '77', 119: '78',
                          120: '79', 121: '80', 122: '81', 123: '82', 124: '83', 125: '84',
                          126: '85', 127: '86', 128: '87', 129: '88', 130: '89', 131: '90',
                          132: '91', 133: '92', 134: '93', 135: '94', 136: '95', 137: '96',
                          138: '97', 139: '98', 140: '99'}
"""
"""
## for Fungi:
pred_mapto_actual_dict = {0: '0', 1: '1', 2: '10', 3: '11', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9'}
"""
"""
## for Birds:
pred_mapto_actual_dict = {0: '202', 1: '203', 2: '204', 3: '205', 4: '206', 5: '207',
                          6: '208', 7: '209', 8: '210', 9: '211', 10: '212', 11: '213',
                          12: '214', 13: '215', 14: '216', 15: '217', 16: '218', 17: '219',
                          18: '220', 19: '221', 20: '222', 21: '223', 22: '224', 23: '225',
                          24: '226', 25: '227', 26: '228', 27: '229', 28: '230', 29: '231',
                          30: '232', 31: '233', 32: '234', 33: '235', 34: '236', 35: '237',
                          36: '238', 37: '239', 38: '240', 39: '241', 40: '242', 41: '243',
                          42: '244', 43: '245', 44: '246', 45: '247', 46: '248', 47: '249',
                          48: '250', 49: '251', 50: '252', 51: '253', 52: '254', 53: '255',
                          54: '256', 55: '257', 56: '258', 57: '259', 58: '260', 59: '261',
                          60: '262', 61: '263', 62: '264', 63: '265', 64: '266', 65: '267',
                          66: '268', 67: '269', 68: '270', 69: '271', 70: '272', 71: '273',
                          72: '274', 73: '275', 74: '276', 75: '277', 76: '278', 77: '279',
                          78: '280', 79: '281', 80: '282', 81: '283', 82: '284', 83: '285',
                          84: '286', 85: '287', 86: '288', 87: '289', 88: '290', 89: '291',
                          90: '292', 91: '293', 92: '294', 93: '295', 94: '296', 95: '297',
                          96: '298', 97: '299', 98: '300', 99: '301', 100: '302', 101: '303',
                          102: '304', 103: '305', 104: '306', 105: '307', 106: '308', 107: '309',
                          108: '310', 109: '311', 110: '312', 111: '313', 112: '314', 113: '315',
                          114: '316', 115: '317', 116: '318', 117: '319', 118: '320', 119: '321',
                          120: '322', 121: '323', 122: '324', 123: '325', 124: '326', 125: '327'}
"""
"""
## for Reptiles:
pred_mapto_actual_dict = {0: '163', 1: '164', 2: '165', 3: '166', 4: '167', 5: '168', 6: '169',
                            7: '170', 8: '171', 9: '172', 10: '173', 11: '174', 12: '175', 13: '176',
                            14: '177', 15: '178', 16: '179', 17: '180', 18: '181', 19: '182', 20: '183',
                            21: '184', 22: '185', 23: '186', 24: '187', 25: '188', 26: '189', 27: '190',
                            28: '191', 29: '192', 30: '193', 31: '194', 32: '195', 33: '196', 34: '197',
                            35: '198', 36: '199', 37: '200', 38: '201'}
"""
"""
## for Amphibians:
pred_mapto_actual_dict = {0: '153', 1: '154', 2: '155', 3: '156', 4: '157', 5: '158', 6: '159', 7: '160', 8: '161', 9: '162'}
"""
"""
## for flowers & UTKFace:
pred_mapto_actual_dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4'}
"""

## for scene:
pred_mapto_actual_dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5'}




model_names = sorted(name for name in models.__dict__
    if name.islower() and not name.startswith("__")
    and callable(models.__dict__[name]))



def get_clsFolders(this_dir):
    for (dirpath, dirnames, filenames) in os.walk(this_dir):
        return dirnames


def get_dataset_normalize():
    # only for the original dataset!!!
    
    if 'Insects' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt:
        print('--> For original iNaturalist Insects dataset step1')
        normalize = transforms.Normalize(mean=[0.489, 0.485, 0.350],
                                         std=[0.187, 0.181, 0.173])
    elif 'Insects' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
        print('--> For cGAN iNaturalist Insects dataset step2')
        normalize = transforms.Normalize(mean=[0.492, 0.484, 0.346],
                                         std=[0.184, 0.178, 0.167])
    
    elif 'Fungi' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt:
        print('--> For original iNaturalist Fungi dataset step1')
        normalize = transforms.Normalize(mean=[0.427, 0.382, 0.318],
                                         std=[0.243, 0.225, 0.212]) # from get_mean_std.py
    elif 'Fungi' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
        print('--> For cGAN iNaturalist Fungi dataset step2')
        """
        ### based on step1 thresh 10:
        normalize = transforms.Normalize(mean=[0.452, 0.407, 0.329],
                                         std=[0.242, 0.226, 0.212]) # from get_mean_std.py
        """
        ### based on step1 thresh 15:
        normalize = transforms.Normalize(mean=[0.463, 0.416, 0.333],
                                         std=[0.241, 0.226, 0.211]) # from get_mean_std.py
    
    elif 'Birds' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        print('--> For original iNaturalist Birds dataset step1')
        normalize = transforms.Normalize(mean=[0.499, 0.520, 0.480],
                                         std=[0.162, 0.166, 0.182]) # from get_mean_std.py
    elif 'Birds' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
        ### based on step1 thresh 10:
        print('--> For cGAN iNaturalist Birds dataset step2')
        normalize = transforms.Normalize(mean=[0.493, 0.515, 0.474],
                                         std=[0.156, 0.161, 0.177]) # from get_mean_std.py
    
    elif 'Reptiles' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        print('--> For original iNaturalist Reptiles dataset step1')
        normalize = transforms.Normalize(mean=[0.506, 0.471, 0.414],
                                         std=[0.191, 0.184, 0.177]) # from get_mean_std.py
    elif 'Reptiles' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
        ### based on step1 thresh 10:
        print('--> For cGAN iNaturalist Reptiles dataset step2')
        normalize = transforms.Normalize(mean=[0.509, 0.473, 0.414],
                                         std=[0.176, 0.170, 0.162]) # from get_mean_std.py
    
    elif 'Amphibians' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        """
        print('--> For original iNaturalist Amphibians dataset step1')
        normalize = transforms.Normalize(mean=[0.475, 0.452, 0.372],
                                         std=[0.194, 0.190, 0.180]) # from get_mean_std.py
        """
        #"""
        print('--> For styleGAN2 iNaturalist Amphibians dataset step1')
        normalize = transforms.Normalize(mean=[0.469, 0.447, 0.364],
                                         std=[0.180, 0.175, 0.164]) # from get_mean_std.py
    	#"""

    elif 'Amphibians' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
    	### based on step1 thresh 10:
        print('--> For cGAN iNaturalist Amphibians dataset step2')
        normalize = transforms.Normalize(mean=[0.462, 0.433, 0.343],
                                         std=[0.186, 0.180, 0.167]) # from get_mean_std.py
    	
    elif 'flowers' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        #"""
        print('--> For orig flowers dataset step1')
        normalize = transforms.Normalize(mean=[0.497, 0.439, 0.311],
                                         std=[0.234, 0.209, 0.209]) # from get_mean_std.py
        #"""
    
    elif 'flowers' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
    	### based on step1 thresh 15:
        print('--> For cGAN flowers dataset step2')
        normalize = transforms.Normalize(mean=[0.515, 0.462, 0.317],
                                         std=[0.233, 0.208, 0.211]) # from get_mean_std.py
    	
    
    elif 'UTKFace' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        print('--> For orig UTKFace dataset step1')
        normalize = transforms.Normalize(mean=[0.637, 0.478, 0.407],
                                         std=[0.182, 0.165, 0.156]) # from get_mean_std.py
    
    elif 'UTKFace' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
    	### based on step1 thresh 25:
        print('--> For cGAN UTKFace dataset step2')
        normalize = transforms.Normalize(mean=[0.643, 0.480, 0.409],
                                         std=[0.185, 0.168, 0.159]) # from get_mean_std.py
    	
    
    elif 'scene' in srcRootDir_GAN_ALL and 'step1' in dstRootDir_opt and 'step2' not in dstRootDir_opt:
        print('--> For orig scene dataset step1')
        normalize = transforms.Normalize(mean=[0.438, 0.463, 0.456],
                                         std=[0.208, 0.203, 0.206]) # from get_mean_std.py
    
    elif 'scene' in srcRootDir_GAN_ALL and 'step2' in dstRootDir_opt:
    	### based on step1 thresh 30:
        print('--> For cGAN scene dataset step2')
        normalize = transforms.Normalize(mean=[0.437, 0.465, 0.457],
                                         std=[0.206, 0.202, 0.205]) # from get_mean_std.py
    	
    
    
    return normalize


def pred_and_gen_pred_prob_dict():
    # generate and save the pred prob_dict file
    
    print("Use GPU: {} for training".format(gpu))
    arch = 'resnet18'
    print("=> creating model '{}'".format(arch))
    model = models.__dict__[arch]()
    
    assert(gpu is not None)
    torch.cuda.set_device(gpu)
    model = model.cuda(gpu)
    
    assert(clsNetwork)
    assert(os.path.isfile(clsNetwork))
    print("=> loading classification model checkpoint '{}'".format(clsNetwork))
    
    # Map model to be loaded to specified single gpu.
    loc = 'cuda:{}'.format(gpu)
    checkpoint = torch.load(clsNetwork, map_location=loc)
    
    model.load_state_dict(checkpoint['state_dict'])
    #optimizer.load_state_dict(checkpoint['optimizer'])
    print("=> loaded classification checkpoint '{}' (epoch {})"
          .format(clsNetwork, checkpoint['epoch']))
    
    cudnn.benchmark = True
    
    normalize = get_dataset_normalize()
    model.eval()
    
    tfms = transforms.Compose([
           transforms.Resize(256),
           transforms.CenterCrop(224),
           transforms.ToTensor(),
           normalize])
    
    for cls_folder in cls_folders:
        subCls_folder = cls_folder + '/'
        print("------------------deal with---------------------")
        print(subCls_folder)
        
        prob_dict = {}
        
        cGAN_file_dir = srcRootDir_GAN_ALL+subCls_folder
        assert(os.path.exists(cGAN_file_dir))
        cGAN_file_list = os.listdir(cGAN_file_dir)
        for cGAN_file in cGAN_file_list:
            print(cGAN_file)
            image1_fullName = cGAN_file_dir + cGAN_file
            assert(os.path.exists(image1_fullName))
            # classify this image1 using model:
            img1 = Image.open(image1_fullName)
            # unsqueeze provides the batch dimension
            img1_tensor = tfms(img1).to('cuda').unsqueeze(0)
            
            output = model(img1_tensor)
            # get prediction:
            topk=(1,)
            maxk = max(topk)
            _, pred = output.topk(maxk, 1, True, True)
            pred = pred.t()
            pred = pred[0].tolist()
            this_pred = pred[0]
            
            # also get the corresponding probability for this pred:
            pred_prob = output[0,this_pred]
            this_pred_prob = pred_prob.tolist()
            
            # IMPORTANT: need modify & re-run!!!!
            this_act = pred_mapto_actual_dict[this_pred]
            if (this_act != cls_folder): #or (this_pred_prob <= 30): # newly modified
                # delete this generated image:
                os.remove(image1_fullName)
            else:
                # also save the probability:
                prob_dict[image1_fullName] = this_pred_prob
            
            #prob_dict[image1_fullName] = this_pred_prob
        
        # save the all_prob_dict to pkl:
        pred_prob_dict_fName = predPklRootDir +'all_prob_dict_'+cls_folder+'.pkl'
        f_pkl = open(pred_prob_dict_fName, 'wb')
        pickle.dump(prob_dict,f_pkl)
        f_pkl.close()
        
    return


def plt_prob_hist():
    # from the all_prob_dict pkl file, plot&save histograms
    # for further analysis:
    
    import matplotlib.pyplot as plt
    cls_folders = get_clsFolders(srcRootDir_GAN_ALL)
    
    for cls_folder in cls_folders:
        # load pkl:
        this_pkl = 'all_prob_dict_'+cls_folder+'.pkl'
        assert(os.path.exists(predPklRootDir+this_pkl))
        f_pkl = open(predPklRootDir+this_pkl,'rb')
        all_prob_dict = pickle.load(f_pkl)
        f_pkl.close()
        
        # plt hist for all the dict values (i.e. prediction probabilities):
        all_probVal_list = list(all_prob_dict.values())
        
        fig = plt.figure()         # create a figure instance
        ax = fig.add_subplot(111)   # and axes
        ax.hist(all_probVal_list, density=False, bins=30)  # density=False would make counts; True would make probability
        plt.ylabel('Count')
        plt.xlabel('Prediction probabilities');
        plt.title(predPklRootDir.split('/')[-1].split('_')[0] +' cls'+cls_folder+' '+dstRootDir_opt.split('/')[-2] +' v2')
        # plt.show()                # this would show the plot, but you can leave it out 
        
        # Save the figure to the current path
        plt.savefig(predPklRootDir+"pred_prob_cls"+cls_folder+".png")
        
    return




if __name__ == '__main__':
    cls_folders = get_clsFolders(srcRootDir_GAN_ALL)
    #cls_folders = ['83'] # just for debug!
    
    if opt == 1:
        # randomly select images generated by cGAN for training later
        for cls_folder in cls_folders:
            print(cls_folder)
            cGAN_file_dir = srcRootDir_GAN_ALL+cls_folder
            assert(os.path.exists(cGAN_file_dir))
            this_dstDir = dstRootDir_opt + cls_folder + '/'
            if not (os.path.exists(this_dstDir)):
                os.mkdir(this_dstDir)
            
            cGAN_file_list = os.listdir(cGAN_file_dir)
            
            orig_file_list = os.listdir(srcRootDir_orig+cls_folder)
            num_orig_imgs = len(orig_file_list)
            
            cGAN_num_needed = total_num_needed - num_orig_imgs
            
            fileList_cGAN_toUSE = random.sample(cGAN_file_list, cGAN_num_needed)
            
            # copy these randomly selected cGAN images to dst dir:
            for cGAN_toUSE in fileList_cGAN_toUSE:
                src_imgName = cGAN_file_dir + '/' + cGAN_toUSE
                assert(os.path.exists(src_imgName))
                dst_imgName = this_dstDir + cGAN_toUSE
            
                shutil.copyfile(src_imgName, dst_imgName)
            
    elif opt == 2:
        # select those whose pred_prob > thresh using a pretrained classifier.
        print('opt = ' + str(opt))
        # if the pred prob_dict file NOT exists: generate and save it:
        if genProb_Flag:
            pred_and_gen_pred_prob_dict()
            # also plot the bar plots:
            plt_prob_hist()
        
        for cls_folder in cls_folders:
            print(cls_folder)
            cGAN_file_dir = srcRootDir_GAN_ALL+cls_folder
            assert(os.path.exists(cGAN_file_dir))
            this_dstDir = dstRootDir_opt + cls_folder + '/'
            if not (os.path.exists(this_dstDir)):
                os.mkdir(this_dstDir)
            
            cGAN_file_list = os.listdir(cGAN_file_dir)
            
            orig_file_list = os.listdir(srcRootDir_orig+cls_folder)
            num_orig_imgs = len(orig_file_list)
            
            cGAN_num_needed = total_num_needed - num_orig_imgs
            
            # load the pred prob_dict file:
            pred_prob_dict_fName = predPklRootDir+'all_prob_dict_'+cls_folder+'.pkl'
            assert(os.path.exists(pred_prob_dict_fName))
            
            f_pkl = open(pred_prob_dict_fName,'rb')
            all_prob_dict = pickle.load(f_pkl)
            f_pkl.close()
            
            for GAN_imgName in all_prob_dict:
                this_pred_prob = all_prob_dict[GAN_imgName]
                if this_pred_prob > prob_thresh: # <- for debug!!! #35:
                    src_GAN_imgName = GAN_imgName
                    assert(os.path.exists(src_GAN_imgName))
                    dst_GAN_imgName = this_dstDir + GAN_imgName.split('/')[-1]
                    #dst_GAN_imgName = dstDir_thresh + 'b-' + GAN_imgName.split('/')[-1].split('a-')[-1] # only for Amphibians b
                    if not (os.path.exists(dst_GAN_imgName)):
                        shutil.copyfile(src_GAN_imgName, dst_GAN_imgName)
            
        # (2) check if resulting GAN-syn img numbers >= the required number;
        #     if NOT, go back and generate more GAN-imgs;
        #     if so, delete the redundant GAN imgs
        for cls_folder in cls_folders:
            print(cls_folder)
            this_dstDir = dstRootDir_opt + cls_folder + '/'
            assert(os.path.exists(this_dstDir))
            GAN_file_list_ = os.listdir(this_dstDir)
            # newly added: remove those orig img names from GAN_file_list_:
            GAN_file_list = []
            for tmp_item in GAN_file_list_:
                if 'seed' in tmp_item:
                    GAN_file_list.append(tmp_item)
            num_GAN_imgs = len(GAN_file_list)
            
            srcDir_orig  =  srcRootDir_orig + cls_folder + '/'
            assert(os.path.exists(srcDir_orig))
            orig_file_list = os.listdir(srcDir_orig)
            num_orig_imgs = len(orig_file_list)
            
            GAN_num_needed = total_num_needed - num_orig_imgs
            
            if (num_GAN_imgs < GAN_num_needed):
                print('***** sub-cls ' + cls_folder + ' GAN imgs num NOT enough!')
            else:
                # delete the redundant GAN imgs:
                num_GAN_toDiscard = num_GAN_imgs - GAN_num_needed
                fileList_GAN_toDiscard = random.sample(GAN_file_list, num_GAN_toDiscard)
                for fileName_GAN_toDiscard in fileList_GAN_toDiscard:
                    fullFileName_GAN_toDiscard = this_dstDir + fileName_GAN_toDiscard
                    assert(os.path.exists(fullFileName_GAN_toDiscard))
                    os.remove(fullFileName_GAN_toDiscard)
    
    #"""
    # (3) copy orig imgs to dst cGAN folder:
    print('copying orig imgs...')
    for cls_folder in cls_folders:
        #print(cls_folder)
        srcDir_orig  =  srcRootDir_orig + cls_folder + '/'
        assert(os.path.exists(srcDir_orig))
        this_dstDir = dstRootDir_opt + cls_folder + '/'
        assert(os.path.exists(this_dstDir))
        
        for (dirpath, dirnames, filenames) in os.walk(srcDir_orig):
            for filename in filenames:
                if (".jpg" in filename):
                    #print("------------------deal with---------------------")
                    #print(filename)
                    src_orig_imgName = srcDir_orig + filename
                    assert(os.path.exists(src_orig_imgName))
                    dst_orig_imgName = this_dstDir + filename
                    if not (os.path.exists(dst_orig_imgName)):
                        shutil.copyfile(src_orig_imgName, dst_orig_imgName)
    #"""



